아래 내용은 검증 필요
Tensorflow Object Detection API SSD mobile v2에서 train과 validation을 동시에 하려면, 다음과 같이 명령어를 입력하면 됩니다1:

리눅스에서
CUDA_VISIBLE_DEVICES="" python ..\models\research\object_detection\model_main_tf2.py --pipeline_config_path=Tensorflow\workspace\models\car-plate\my_ssd_mobnet\pipeline.config --model_dir=Tensorflow\workspace\models\car-plate\my_ssd_mobnet --checkpoint_dir=Tensorflow\workspace\models\car-plate\my_ssd_mobnet --sample_1_of_n_eval_examples=1 --alsologtostderr
윈도우에서  
evaluation
set CUDA_VISIBLE_DEVICES="" & python ..\models\research\object_detection\model_main_tf2.py --pipeline_config_path=Tensorflow\workspace\models\car-plate\my_ssd_mobnet\pipeline.config --model_dir=Tensorflow\workspace\models\car-plate\my_ssd_mobnet --checkpoint_dir=Tensorflow\workspace\models\car-plate\my_ssd_mobnet --sample_1_of_n_eval_examples=1 --alsologtostderr

python model_main_tf2.py --model_dir=models/my_ssd_mobilenet_v2 --pipeline_config_path=models/my_ssd_mobilenet_v2/pipeline.config --num_train_steps=46875 --sample_1_of_n_eval_examples=1 --alsologtostderr

여기서 --model_dir은 모델이 저장될 폴더 경로, --pipeline_config_path는 모델 구성 파일 경로, --num_train_steps는 학습할 스텝 수, --sample_1_of_n_eval_examples는 validation 데이터셋에서 몇 번째 예제를 사용할지를 결정하는 변수입니다1.

#python ..\models\research\object_detection\model_main_tf2.py --model_dir=Tensorflow\workspace\models\car-plate\my_ssd_mobnet --pipeline_config_path=Tensorflow\workspace\models\car-plate\my_ssd_mobnet\pipeline.config --num_train_steps=46875 --checkpoint_every_n=200 --sample_1_of_n_eval_examples=1 --alsologtostderr
car-plate 트레이닝 명령어.
python ..\models\research\object_detection\model_main_tf2.py --model_dir=Tensorflow\workspace\models\car-plate\my_ssd_mobnet --pipeline_config_path=Tensorflow\workspace\models\car-plate\my_ssd_mobnet\pipeline.config --num_train_steps=46875 --checkpoint_every_n=1000  --alsologtostderr
evaluation
set CUDA_VISIBLE_DEVICES="" & python ..\models\research\object_detection\model_main_tf2.py --pipeline_config_path=Tensorflow\workspace\models\car-plate\my_ssd_mobnet\pipeline.config --model_dir=Tensorflow\workspace\models\car-plate\my_ssd_mobnet --checkpoint_dir=Tensorflow\workspace\models\car-plate\my_ssd_mobnet --sample_1_of_n_eval_examples=1 --alsologtostderr




python ..\models\research\object_detection\model_main_tf2.py --model_dir=Tensorflow\workspace\models\plate\my_ssd_mobnet --pipeline_config_path=Tensorflow\workspace\models\plate\my_ssd_mobnet\pipeline.config --num_train_steps=10000
train
python ..\models\research\object_detection\model_main_tf2.py --model_dir=Tensorflow\workspace\models\plateimage\my_ssd_mobnet --pipeline_config_path=Tensorflow\workspace\models\plateimage\my_ssd_mobnet\pipeline.config --num_train_steps=60000 --checkpoint_every_n=2500  --alsologtostderr
evaluation
set CUDA_VISIBLE_DEVICES="" & python ..\models\research\object_detection\model_main_tf2.py --pipeline_config_path=Tensorflow\workspace\models\plateimage\my_ssd_mobnet\pipeline.config --model_dir=Tensorflow\workspace\models\plateimage\my_ssd_mobnet --checkpoint_dir=Tensorflow\workspace\models\plateimage\my_ssd_mobnet --sample_1_of_n_eval_examples=1 --alsologtostderr
이륜차
python ..\models\research\object_detection\model_main_tf2.py --model_dir=Tensorflow\workspace\models\mplateimage\my_ssd_mobnet --pipeline_config_path=Tensorflow\workspace\models\mplateimage\my_ssd_mobnet\pipeline.config --num_train_steps=16785 --checkpoint_every_n=1000  --alsologtostderr
evaluation
set CUDA_VISIBLE_DEVICES="" & python ..\models\research\object_detection\model_main_tf2.py --pipeline_config_path=Tensorflow\workspace\models\mplateimage\my_ssd_mobnet\pipeline.config --model_dir=Tensorflow\workspace\models\mplateimage\my_ssd_mobnet --checkpoint_dir=Tensorflow\workspace\models\mplateimage\my_ssd_mobnet --sample_1_of_n_eval_examples=1 --alsologtostderr




check point를 saved model로 변환
Tf2
1.)
python ..\models\research\object_detection\exporter_main_v2.py --input_type image_tensor --pipeline_config_path Tensorflow\workspace\models\plateimage\my_ssd_mobnet\pipeline.config --trained_checkpoint_dir Tensorflow\workspace\models\plateimage\my_ssd_mobnet --output_directory .\exported-models\my_model

2.) onnx용으로는 input_type이 float_image_tensor로 되어야 함.
python ..\models\research\object_detection\exporter_main_v2.py --input_type float_image_tensor --pipeline_config_path Tensorflow\workspace\models\plateimage\my_ssd_mobnet\pipeline.config --trained_checkpoint_dir Tensorflow\workspace\models\plateimage\my_ssd_mobnet --output_directory .\exported-models\my_model

Tf1
python ..\models\research\object_detection\export_inference_graph.py --input_type image_tensor --pipeline_config_path Tensorflow\workspace\models\car-plate\my_ssd_mobnet\pipeline.config --trained_checkpoint_prefix Tensorflow\workspace\models\car-plate\my_ssd_mobnet\ckpt-11 --output_directory inference_graph



saved_model_cli.exe show --dir c:\SPB_Data\RealTimeObjectDetection-main\exported-models\my_model\saved_model --tag_set serve --signature_def serving_default
The given SavedModel SignatureDef contains the following input(s):
  inputs['input_tensor'] tensor_info:
      dtype: DT_FLOAT
      shape: (-1, -1, -1, 3)
      name: serving_default_input_tensor:0
The given SavedModel SignatureDef contains the following output(s):
  outputs['detection_anchor_indices'] tensor_info:
      dtype: DT_FLOAT
      shape: (-1, 10)
      name: StatefulPartitionedCall:0
  outputs['detection_boxes'] tensor_info:
      dtype: DT_FLOAT
      shape: (-1, 10, 4)
      name: StatefulPartitionedCall:1
  outputs['detection_classes'] tensor_info:
      dtype: DT_FLOAT
      shape: (-1, 10)
      name: StatefulPartitionedCall:2
  outputs['detection_multiclass_scores'] tensor_info:
      dtype: DT_FLOAT
      shape: (-1, 10, 11)
      name: StatefulPartitionedCall:3
  outputs['detection_scores'] tensor_info:
      dtype: DT_FLOAT
      shape: (-1, 10)
      name: StatefulPartitionedCall:4
  outputs['num_detections'] tensor_info:
      dtype: DT_FLOAT
      shape: (-1)
      name: StatefulPartitionedCall:5
  outputs['raw_detection_boxes'] tensor_info:
      dtype: DT_FLOAT
      shape: (-1, -1, 4)
      name: StatefulPartitionedCall:6
  outputs['raw_detection_scores'] tensor_info:
      dtype: DT_FLOAT
      shape: (-1, -1, 11)
      name: StatefulPartitionedCall:7
Method name is: tensorflow/serving/predict

(object_detection_api) C:\venvs\object_detection_api\Scripts>



(object_detection_api) C:\venvs\object_detection_api\Scripts>saved_model_cli.exe show --dir c:\SPB_Data\RealTimeObjectDetection-main\exported-models\my_model\saved_model --tag_set serve --signature_def serving_default
The given SavedModel SignatureDef contains the following input(s):
  inputs['input_tensor'] tensor_info:
      dtype: DT_UINT8
      shape: (1, -1, -1, 3)
      name: serving_default_input_tensor:0
The given SavedModel SignatureDef contains the following output(s):
  outputs['detection_anchor_indices'] tensor_info:
      dtype: DT_FLOAT
      shape: (1, 10)
      name: StatefulPartitionedCall:0
  outputs['detection_boxes'] tensor_info:
      dtype: DT_FLOAT
      shape: (1, 10, 4)
      name: StatefulPartitionedCall:1
  outputs['detection_classes'] tensor_info:
      dtype: DT_FLOAT
      shape: (1, 10)
      name: StatefulPartitionedCall:2
  outputs['detection_multiclass_scores'] tensor_info:
      dtype: DT_FLOAT
      shape: (1, 10, 11)
      name: StatefulPartitionedCall:3
  outputs['detection_scores'] tensor_info:
      dtype: DT_FLOAT
      shape: (1, 10)
      name: StatefulPartitionedCall:4
  outputs['num_detections'] tensor_info:
      dtype: DT_FLOAT
      shape: (1)
      name: StatefulPartitionedCall:5
  outputs['raw_detection_boxes'] tensor_info:
      dtype: DT_FLOAT
      shape: (1, 85360, 4)
      name: StatefulPartitionedCall:6
  outputs['raw_detection_scores'] tensor_info:
      dtype: DT_FLOAT
      shape: (1, 85360, 11)
      name: StatefulPartitionedCall:7
Method name is: tensorflow/serving/predict

(object_detection_api) C:\venvs\object_detection_api\Scripts>


tensorflow --opset 11까지만 지원한다는 얘기가 있음.
python -m tf2onnx.convert --saved-model .\exported-models\my_model\saved-model --opset 13 --output model.onnx

python -m tf2onnx.convert --saved-model C:\SPB_Data\RealTimeObjectDetection-main\exported-models\my_model\saved_model --opset 11 --fold_const --output model.onnx


#debug command
debugfile("../models/research/object_detection/model_main_tf2.py", "--model_dir=Tensorflow/workspace/models/plateimage/my_ssd_mobnet --pipeline_config_path=Tensorflow/workspace/models/plateimage/my_ssd_mobnet/pipeline.config --num_train_steps=10000")



tensorboard --logdir ./Tensorflow/workspace/models/plateimage/my_ssd_mobnet/train


trtexec --onnx=model.onnx --saveEngine=engine.trt --verbose

trtexec --explicitBatch --onnx=model.onnx --saveEngine=model.engine


#object detection model 사용시
onnx 파일 만들기...
python .\tensorflow_object_detection_api\create_onnx.py --pipeline_config .\Tensorflow\workspace\models\plateimage\my_ssd_mobnet\pipeline.config --saved_model .\exported-models\my_model\saved_model --onnx .\exported-models\my_model\model.onnx
tensorrt 파일 만들기
python .\tensorflow_object_detection_api\build_engine.py --onnx .\exported-models\my_model\model.onnx --engine .\exported-models\my_model\engine.trt --precision fp16
inference 테스트

python .\tensorflow_object_detection_api\infer.py --engine .\exported-models\my_model\engine.trt --input .\Tensorflow\workspace\images\plateimage\test --output .\Tensorflow\workspace\images\plateimage\result --preprocessor fixed_shape_resizer --labels .\tensorflow_object_detection_api\plateimage_label.txt



# car-plate tensorflow model 만들기
python ..\models\research\object_detection\exporter_main_v2.py --input_type float_image_tensor --pipeline_config_path Tensorflow\workspace\models\car-plate\my_ssd_mobnet\pipeline.config --trained_checkpoint_dir Tensorflow\workspace\models\car-plate\my_ssd_mobnet --output_directory .\exported-models\car-plate
#onnx 만들기
python .\tensorflow_object_detection_api\create_onnx.py --pipeline_config .\Tensorflow\workspace\models\car-plate\my_ssd_mobnet\pipeline.config --saved_model .\exported-models\car-plate\saved_model --onnx .\exported-models\car-plate\model.onnx -f NCHW
#tensorrt 만들기
python .\tensorflow_object_detection_api\build_engine.py --onnx .\exported-models\car-plate\model.onnx --engine .\exported-models\car-plate\engine.trt --precision fp16


# plate tensorflow model 만들기
python ..\models\research\object_detection\exporter_main_v2.py --input_type float_image_tensor --pipeline_config_path Tensorflow\workspace\models\plate\my_ssd_mobnet\pipeline.config --trained_checkpoint_dir Tensorflow\workspace\models\plate\my_ssd_mobnet --output_directory .\exported-models\plate
#onnx 만들기
python .\tensorflow_object_detection_api\create_onnx.py --pipeline_config .\Tensorflow\workspace\models\plate\my_ssd_mobnet\pipeline.config --saved_model .\exported-models\plate\saved_model --onnx .\exported-models\plate\model.onnx -f NCHW
#tensorrt 만들기
python .\tensorflow_object_detection_api\build_engine.py --onnx .\exported-models\plate\model.onnx --engine .\exported-models\plate\engine.trt --precision fp16


#plateimage tensorflow model 만들기
python ..\models\research\object_detection\exporter_main_v2.py --input_type float_image_tensor --pipeline_config_path Tensorflow\workspace\models\plateimage\my_ssd_mobnet\pipeline.config --trained_checkpoint_dir Tensorflow\workspace\models\plateimage\my_ssd_mobnet --output_directory .\exported-models\plateimage
#onnx 만들기
python .\tensorflow_object_detection_api\create_onnx.py --pipeline_config .\Tensorflow\workspace\models\plateimage\my_ssd_mobnet\pipeline.config --saved_model .\exported-models\plateimage\saved_model --onnx .\exported-models\plateimage\model.onnx -f NCHW
#tensorrt 만들기
python .\tensorflow_object_detection_api\build_engine.py --onnx .\exported-models\plateimage\model.onnx --engine .\exported-models\plateimage\engine.trt --precision fp16


#이륜차 번호판 mplateimage tensorflow model 만들기
python ..\models\research\object_detection\exporter_main_v2.py --input_type float_image_tensor --pipeline_config_path Tensorflow\workspace\models\mplateimage\my_ssd_mobnet\pipeline.config --trained_checkpoint_dir Tensorflow\workspace\models\mplateimage\my_ssd_mobnet --output_directory .\exported-models\motor_plateimage
#onnx 만들기
python .\tensorflow_object_detection_api\create_onnx.py --pipeline_config .\Tensorflow\workspace\models\mplateimage\my_ssd_mobnet\pipeline.config --saved_model .\exported-models\motor_plateimage\saved_model --onnx .\exported-models\motor_plateimage\model.onnx -f NCHW
#tensorrt 만들기
python .\tensorflow_object_detection_api\build_engine.py --onnx .\exported-models\motor_plateimage\model.onnx --engine .\exported-models\motor_plateimage\engine.trt --precision fp16



채널 순서 바꾸기

python .\tensorflow_object_detection_api\create_onnx.py --pipeline_config .\Tensorflow\workspace\models\plateimage\my_ssd_mobnet\pipeline.config --saved_model .\exported-models\plateimage\saved_model --onnx .\exported-models\plateimage\model.onnx -f NCHW


문자 onnx 저장
python -m tf2onnx.convert --saved-model .\exported-models\ch_model\saved_model --opset 13 --output .\exported-models\ch_model\model.onnx --inputs resnet50_input:0[1,224,224,3] --inputs-as-nchw resnet50_input:0
python .\tensorflow_object_detection_api\build_engine.py --onnx .\exported-models\ch_model\model.onnx --engine .\exported-models\ch_model\engine.trt --precision fp16

hr onnx 저장
python -m tf2onnx.convert --saved-model .\exported-models\hr_model\saved_model --opset 13 --output .\exported-models\hr_model\model.onnx --inputs resnet50_input:0[1,224,224,3] --inputs-as-nchw resnet50_input:0
python .\tensorflow_object_detection_api\build_engine.py --onnx .\exported-models\hr_model\model.onnx --engine .\exported-models\hr_model\engine.trt --precision fp16

vr onnx 저장
python -m tf2onnx.convert --saved-model .\exported-models\vr_model\saved_model --opset 13 --output .\exported-models\vr_model\model.onnx --inputs resnet50_input:0[1,224,224,3] --inputs-as-nchw resnet50_input:0
python .\tensorflow_object_detection_api\build_engine.py --onnx .\exported-models\vr_model\model.onnx --engine .\exported-models\vr_model\engine.trt --precision fp16

or onnx 저장
python -m tf2onnx.convert --saved-model .\exported-models\or_model\saved_model --opset 13 --output .\exported-models\or_model\model.onnx --inputs resnet50_input:0[1,224,224,3] --inputs-as-nchw resnet50_input:0
python .\tensorflow_object_detection_api\build_engine.py --onnx .\exported-models\or_model\model.onnx --engine .\exported-models\or_model\engine.trt --precision fp16


이륜차 문자 onnx 저장
python -m tf2onnx.convert --saved-model .\exported-models\motor_ch_model\saved_model --opset 13 --output .\exported-models\motor_ch_model\model.onnx --inputs resnet50_input:0[1,224,224,3] --inputs-as-nchw resnet50_input:0
python .\tensorflow_object_detection_api\build_engine.py --onnx .\exported-models\motor_ch_model\model.onnx --engine .\exported-models\motor_ch_model\engine.trt --precision fp16

이륜차 hr onnx 저장
python -m tf2onnx.convert --saved-model .\exported-models\motor_hr_model\saved_model --opset 13 --output .\exported-models\motor_hr_model\model.onnx --inputs resnet50_input:0[1,224,224,3] --inputs-as-nchw resnet50_input:0
python .\tensorflow_object_detection_api\build_engine.py --onnx .\exported-models\motor_hr_model\model.onnx --engine .\exported-models\motor_hr_model\engine.trt --precision fp16


char crnn onnx 저장
python -m tf2onnx.convert --saved-model .\exported-models\char_crnn_model\saved_model --opset 13 --output .\exported-models\char_crnn_model\model.onnx --inputs image:0[1,224,224,3] --inputs-as-nchw image:0
python .\tensorflow_object_detection_api\build_engine.py --onnx .\exported-models\char_crnn_model\model.onnx --engine .\exported-models\char_crnn_model\engine.trt --precision fp16

reg crnn onnx 저장
python -m tf2onnx.convert --saved-model .\exported-models\reg_crnn_model\saved_model --opset 13 --output .\exported-models\reg_crnn_model\model.onnx --inputs image:0[1,224,224,3] --inputs-as-nchw image:0
python .\tensorflow_object_detection_api\build_engine.py --onnx .\exported-models\reg_crnn_model\model.onnx --engine .\exported-models\reg_crnn_model\engine.trt --precision fp16