python ..\models\research\object_detection\model_main_tf2.py --model_dir=Tensorflow\workspace\models\plate\my_ssd_mobnet --pipeline_config_path=Tensorflow\workspace\models\plate\my_ssd_mobnet\pipeline.config --num_train_steps=10000

python ..\models\research\object_detection\model_main_tf2.py --model_dir=Tensorflow\workspace\models\plateimage\my_ssd_mobnet --pipeline_config_path=Tensorflow\workspace\models\plateimage\my_ssd_mobnet\pipeline.config --num_train_steps=100000

check point를 saved model로 변환
Tf2
1.)
python ..\models\research\object_detection\exporter_main_v2.py --input_type image_tensor --pipeline_config_path Tensorflow\workspace\models\plateimage\my_ssd_mobnet\pipeline.config --trained_checkpoint_dir Tensorflow\workspace\models\plateimage\my_ssd_mobnet --output_directory .\exported-models\my_model

2.) onnx용으로는 input_type이 float_image_tensor로 되어야 함.
python ..\models\research\object_detection\exporter_main_v2.py --input_type float_image_tensor --pipeline_config_path Tensorflow\workspace\models\plateimage\my_ssd_mobnet\pipeline.config --trained_checkpoint_dir Tensorflow\workspace\models\plateimage\my_ssd_mobnet --output_directory .\exported-models\my_model

Tf1
python ..\models\research\object_detection\export_inference_graph.py --input_type image_tensor --pipeline_config_path Tensorflow\workspace\models\car-plate\my_ssd_mobnet\pipeline.config --trained_checkpoint_prefix Tensorflow\workspace\models\car-plate\my_ssd_mobnet\ckpt-11 --output_directory inference_graph



saved_model_cli.exe show --dir c:\SPB_Data\RealTimeObjectDetection-main\exported-models\my_model\saved_model --tag_set serve --signature_def serving_default
The given SavedModel SignatureDef contains the following input(s):
  inputs['input_tensor'] tensor_info:
      dtype: DT_FLOAT
      shape: (-1, -1, -1, 3)
      name: serving_default_input_tensor:0
The given SavedModel SignatureDef contains the following output(s):
  outputs['detection_anchor_indices'] tensor_info:
      dtype: DT_FLOAT
      shape: (-1, 10)
      name: StatefulPartitionedCall:0
  outputs['detection_boxes'] tensor_info:
      dtype: DT_FLOAT
      shape: (-1, 10, 4)
      name: StatefulPartitionedCall:1
  outputs['detection_classes'] tensor_info:
      dtype: DT_FLOAT
      shape: (-1, 10)
      name: StatefulPartitionedCall:2
  outputs['detection_multiclass_scores'] tensor_info:
      dtype: DT_FLOAT
      shape: (-1, 10, 11)
      name: StatefulPartitionedCall:3
  outputs['detection_scores'] tensor_info:
      dtype: DT_FLOAT
      shape: (-1, 10)
      name: StatefulPartitionedCall:4
  outputs['num_detections'] tensor_info:
      dtype: DT_FLOAT
      shape: (-1)
      name: StatefulPartitionedCall:5
  outputs['raw_detection_boxes'] tensor_info:
      dtype: DT_FLOAT
      shape: (-1, -1, 4)
      name: StatefulPartitionedCall:6
  outputs['raw_detection_scores'] tensor_info:
      dtype: DT_FLOAT
      shape: (-1, -1, 11)
      name: StatefulPartitionedCall:7
Method name is: tensorflow/serving/predict

(object_detection_api) C:\venvs\object_detection_api\Scripts>



(object_detection_api) C:\venvs\object_detection_api\Scripts>saved_model_cli.exe show --dir c:\SPB_Data\RealTimeObjectDetection-main\exported-models\my_model\saved_model --tag_set serve --signature_def serving_default
The given SavedModel SignatureDef contains the following input(s):
  inputs['input_tensor'] tensor_info:
      dtype: DT_UINT8
      shape: (1, -1, -1, 3)
      name: serving_default_input_tensor:0
The given SavedModel SignatureDef contains the following output(s):
  outputs['detection_anchor_indices'] tensor_info:
      dtype: DT_FLOAT
      shape: (1, 10)
      name: StatefulPartitionedCall:0
  outputs['detection_boxes'] tensor_info:
      dtype: DT_FLOAT
      shape: (1, 10, 4)
      name: StatefulPartitionedCall:1
  outputs['detection_classes'] tensor_info:
      dtype: DT_FLOAT
      shape: (1, 10)
      name: StatefulPartitionedCall:2
  outputs['detection_multiclass_scores'] tensor_info:
      dtype: DT_FLOAT
      shape: (1, 10, 11)
      name: StatefulPartitionedCall:3
  outputs['detection_scores'] tensor_info:
      dtype: DT_FLOAT
      shape: (1, 10)
      name: StatefulPartitionedCall:4
  outputs['num_detections'] tensor_info:
      dtype: DT_FLOAT
      shape: (1)
      name: StatefulPartitionedCall:5
  outputs['raw_detection_boxes'] tensor_info:
      dtype: DT_FLOAT
      shape: (1, 85360, 4)
      name: StatefulPartitionedCall:6
  outputs['raw_detection_scores'] tensor_info:
      dtype: DT_FLOAT
      shape: (1, 85360, 11)
      name: StatefulPartitionedCall:7
Method name is: tensorflow/serving/predict

(object_detection_api) C:\venvs\object_detection_api\Scripts>


tensorflow --opset 11까지만 지원한다는 얘기가 있음.
python -m tf2onnx.convert --saved-model .\exported-models\my_model\saved-model --opset 13 --output model.onnx

python -m tf2onnx.convert --saved-model C:\SPB_Data\RealTimeObjectDetection-main\exported-models\my_model\saved_model --opset 11 --fold_const --output model.onnx


#debug command
debugfile("../models/research/object_detection/model_main_tf2.py", "--model_dir=Tensorflow/workspace/models/plateimage/my_ssd_mobnet --pipeline_config_path=Tensorflow/workspace/models/plateimage/my_ssd_mobnet/pipeline.config --num_train_steps=10000")



tensorboard --logdir ./Tensorflow/workspace/models/plateimage/my_ssd_mobnet/train


trtexec --onnx=model.onnx --saveEngine=engine.trt --verbose

trtexec --explicitBatch --onnx=model.onnx --saveEngine=model.engine


#object detection model 사용시
onnx 파일 만들기...
python .\tensorflow_object_detection_api\create_onnx.py --pipeline_config .\Tensorflow\workspace\models\plateimage\my_ssd_mobnet\pipeline.config --saved_model .\exported-models\my_model\saved_model --onnx .\exported-models\my_model\model.onnx
tensorrt 파일 만들기
python .\tensorflow_object_detection_api\build_engine.py --onnx .\exported-models\my_model\model.onnx --engine .\exported-models\my_model\engine.trt --precision fp16
inference 테스트

python .\tensorflow_object_detection_api\infer.py --engine .\exported-models\my_model\engine.trt --input .\Tensorflow\workspace\images\plateimage\test --output .\Tensorflow\workspace\images\plateimage\result --preprocessor fixed_shape_resizer --labels .\tensorflow_object_detection_api\plateimage_label.txt



# car-plate tensorflow model 만들기
python ..\models\research\object_detection\exporter_main_v2.py --input_type float_image_tensor --pipeline_config_path Tensorflow\workspace\models\car-plate\my_ssd_mobnet\pipeline.config --trained_checkpoint_dir Tensorflow\workspace\models\car-plate\my_ssd_mobnet --output_directory .\exported-models\car-plate
#onnx 만들기
python .\tensorflow_object_detection_api\create_onnx.py --pipeline_config .\Tensorflow\workspace\models\car-plate\my_ssd_mobnet\pipeline.config --saved_model .\exported-models\car-plate\saved_model --onnx .\exported-models\car-plate\model.onnx -f NCHW
#tensorrt 만들기
python .\tensorflow_object_detection_api\build_engine.py --onnx .\exported-models\car-plate\model.onnx --engine .\exported-models\car-plate\engine.trt --precision fp16


# plate tensorflow model 만들기
python ..\models\research\object_detection\exporter_main_v2.py --input_type float_image_tensor --pipeline_config_path Tensorflow\workspace\models\plate\my_ssd_mobnet\pipeline.config --trained_checkpoint_dir Tensorflow\workspace\models\plate\my_ssd_mobnet --output_directory .\exported-models\plate
#onnx 만들기
python .\tensorflow_object_detection_api\create_onnx.py --pipeline_config .\Tensorflow\workspace\models\plate\my_ssd_mobnet\pipeline.config --saved_model .\exported-models\plate\saved_model --onnx .\exported-models\plate\model.onnx -f NCHW
#tensorrt 만들기
python .\tensorflow_object_detection_api\build_engine.py --onnx .\exported-models\plate\model.onnx --engine .\exported-models\plate\engine.trt --precision fp16


#plateimage tensorflow model 만들기
python ..\models\research\object_detection\exporter_main_v2.py --input_type float_image_tensor --pipeline_config_path Tensorflow\workspace\models\plateimage\my_ssd_mobnet\pipeline.config --trained_checkpoint_dir Tensorflow\workspace\models\plateimage\my_ssd_mobnet --output_directory .\exported-models\plateimage
#onnx 만들기
python .\tensorflow_object_detection_api\create_onnx.py --pipeline_config .\Tensorflow\workspace\models\plateimage\my_ssd_mobnet\pipeline.config --saved_model .\exported-models\plateimage\saved_model --onnx .\exported-models\plateimage\model.onnx -f NCHW
#tensorrt 만들기
python .\tensorflow_object_detection_api\build_engine.py --onnx .\exported-models\plateimage\model.onnx --engine .\exported-models\plateimage\engine.trt --precision fp16


#이륜차 번호판 mplateimage tensorflow model 만들기
python ..\models\research\object_detection\exporter_main_v2.py --input_type float_image_tensor --pipeline_config_path Tensorflow\workspace\models\mplateimage\my_ssd_mobnet\pipeline.config --trained_checkpoint_dir Tensorflow\workspace\models\mplateimage\my_ssd_mobnet --output_directory .\exported-models\motor_plateimage
#onnx 만들기
python .\tensorflow_object_detection_api\create_onnx.py --pipeline_config .\Tensorflow\workspace\models\mplateimage\my_ssd_mobnet\pipeline.config --saved_model .\exported-models\motor_plateimage\saved_model --onnx .\exported-models\motor_plateimage\model.onnx -f NCHW
#tensorrt 만들기
python .\tensorflow_object_detection_api\build_engine.py --onnx .\exported-models\motor_plateimage\model.onnx --engine .\exported-models\motor_plateimage\engine.trt --precision fp16



채널 순서 바꾸기

python .\tensorflow_object_detection_api\create_onnx.py --pipeline_config .\Tensorflow\workspace\models\plateimage\my_ssd_mobnet\pipeline.config --saved_model .\exported-models\plateimage\saved_model --onnx .\exported-models\plateimage\model.onnx -f NCHW


문자 onnx 저장
python -m tf2onnx.convert --saved-model .\exported-models\ch_model\saved_model --opset 13 --output .\exported-models\ch_model\model.onnx --inputs resnet50_input:0[1,224,224,3] --inputs-as-nchw resnet50_input:0
python .\tensorflow_object_detection_api\build_engine.py --onnx .\exported-models\ch_model\model.onnx --engine .\exported-models\ch_model\engine.trt --precision fp16

hr onnx 저장
python -m tf2onnx.convert --saved-model .\exported-models\hr_model\saved_model --opset 13 --output .\exported-models\hr_model\model.onnx --inputs resnet50_input:0[1,224,224,3] --inputs-as-nchw resnet50_input:0
python .\tensorflow_object_detection_api\build_engine.py --onnx .\exported-models\hr_model\model.onnx --engine .\exported-models\hr_model\engine.trt --precision fp16

vr onnx 저장
python -m tf2onnx.convert --saved-model .\exported-models\vr_model\saved_model --opset 13 --output .\exported-models\vr_model\model.onnx --inputs resnet50_input:0[1,224,224,3] --inputs-as-nchw resnet50_input:0
python .\tensorflow_object_detection_api\build_engine.py --onnx .\exported-models\vr_model\model.onnx --engine .\exported-models\vr_model\engine.trt --precision fp16

or onnx 저장
python -m tf2onnx.convert --saved-model .\exported-models\or_model\saved_model --opset 13 --output .\exported-models\or_model\model.onnx --inputs resnet50_input:0[1,224,224,3] --inputs-as-nchw resnet50_input:0
python .\tensorflow_object_detection_api\build_engine.py --onnx .\exported-models\or_model\model.onnx --engine .\exported-models\or_model\engine.trt --precision fp16


이륜차 문자 onnx 저장
python -m tf2onnx.convert --saved-model .\exported-models\motor_ch_model\saved_model --opset 13 --output .\exported-models\motor_ch_model\model.onnx --inputs resnet50_input:0[1,224,224,3] --inputs-as-nchw resnet50_input:0
python .\tensorflow_object_detection_api\build_engine.py --onnx .\exported-models\motor_ch_model\model.onnx --engine .\exported-models\motor_ch_model\engine.trt --precision fp16

이륜차 hr onnx 저장
python -m tf2onnx.convert --saved-model .\exported-models\motor_hr_model\saved_model --opset 13 --output .\exported-models\motor_hr_model\model.onnx --inputs resnet50_input:0[1,224,224,3] --inputs-as-nchw resnet50_input:0
python .\tensorflow_object_detection_api\build_engine.py --onnx .\exported-models\motor_hr_model\model.onnx --engine .\exported-models\motor_hr_model\engine.trt --precision fp16